# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Setup

```bash
pip install -e ".[dev]"
```

No external API keys or environment variables required — all data sources are public and configured in `src/config.py`.

## Common Commands

```bash
# Run the full pipeline for a source
postal-codes download --source nar
postal-codes process --source nar
postal-codes diff --source nar

# Or in one shot
postal-codes refresh --source nar

# Reprocess from raw files (e.g. after code changes)
postal-codes reprocess --source nar --rebuild-db

# Reclassify city changes after updating rules
postal-codes classify

# Start the local web server (http://127.0.0.1:8080)
postal-codes serve

# Regenerate static JSON for GitHub Pages (outputs to docs/data/)
postal-codes generate-static

# Print DB stats
postal-codes stats

# Add -v to any command for verbose logging
postal-codes -v diff --source nar
```

## Architecture

### Data Pipeline

```
Download → Process → Diff → Classify → Serve / Generate-static
```

1. **Download** (`downloader.py`): Fetches NAR ZIPs from Statistics Canada, Geocoder.ca CSV, GeoNames ZIP. Raw files go to `data/raw/`.
2. **Process** (`parser_nar.py`, `parser_geocoder.py`, `parser_geonames.py`): Parses raw files in chunks and loads into `postal_code_snapshots` table. Saves parquet intermediates to `data/processed/`.
3. **Diff** (`differ.py`): Compares consecutive snapshots pair-by-pair. Writes to `postal_code_changes` and rebuilds `postal_code_summary`. Detects 5 change types: `added`, `removed`, `city_changed`, `csd_changed`, `location_shifted`.
4. **Classify** (`classifier.py`): Sub-classifies `city_changed` rows into 8 subtypes (encoding, accent, punctuation, spacing, abbreviation, boundary, rename, substantive) using rules in `data/city_change_rules.json`.
5. **Serve** (`web/app.py`, `web/api.py`): FastAPI server with JSON API + static HTML/JS frontend (no build step).
6. **Generate-static** (`static_generator.py`): Exports summary/timeline/province/change JSON files to `docs/data/` for GitHub Pages.

### Database Schema (SQLite, `data/postal_codes.db`)

| Table | Purpose |
|---|---|
| `data_sources` | Download/processing metadata per source and period |
| `postal_code_snapshots` | One row per (postal_code, snapshot_date, source_type) |
| `postal_code_changes` | All detected changes with change_type and change_subtype |
| `postal_code_summary` | Aggregated current state per postal code (rebuilt after each diff) |

### Data Sources

- **NAR (primary)**: 6 snapshots from Statistics Canada (2022, 2023, 2024-06, 2024-12, 2025-07, 2025-12), ~900K unique postal codes each, chunked at 500K rows.
- **Geocoder.ca (secondary)**: Current crowdsourced data.
- **GeoNames (tertiary)**: Global Canada extract.

### Key Files

| File | Role |
|---|---|
| `src/config.py` | All URLs, province mappings, file paths, constants |
| `src/db.py` | Schema DDL, connection setup (WAL mode), shared query helpers |
| `src/cli.py` | Click CLI — all commands and their options |
| `src/differ.py` | Core change detection logic |
| `src/classifier.py` | City change sub-classification with rule engine |
| `src/web/api.py` | FastAPI route definitions |
| `data/city_change_rules.json` | Rules for classifying city name changes |

### Static Site

`docs/` contains the GitHub Pages site. `docs/data/` holds the exported JSON (generated by `postal-codes generate-static`). The frontend in `src/web/static/` is plain HTML/CSS/JS with no build step.
